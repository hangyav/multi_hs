{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc1abc01",
   "metadata": {},
   "source": [
    "Based on: https://colab.research.google.com/github/Adapter-Hub/adapter-transformers/blob/master/notebooks/03_Adapter_Fusion.ipynb#scrollTo=INW7UEhC-I6b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d467bea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import BertTokenizer, BertConfig, BertModelWithHeads\n",
    "from transformers import TrainingArguments, AdapterTrainer, EvalPrediction\n",
    "from transformers.adapters.composition import Fuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "206abf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset super_glue (/nfs/datz/hangyav/.huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4360da181c41ca9c9010504ac85634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'train': 250, 'validation': 56, 'test': 250}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"super_glue\", \"cb\")\n",
    "dataset.num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef7a5c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /nfs/datz/hangyav/.huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-e6748383b0d7249e.arrow\n",
      "Loading cached processed dataset at /nfs/datz/hangyav/.huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-68e640accb1bbd4c.arrow\n",
      "Loading cached processed dataset at /nfs/datz/hangyav/.huggingface/datasets/super_glue/cb/1.0.2/d040c658e2ddef6934fdd97deb45c777b6ff50c524781ea434e7219b56a428a7/cache-43c019c30b40a14d.arrow\n",
      "/tmp/ipykernel_3035702/4175906235.py:16: FutureWarning: rename_column_ is deprecated and will be removed in the next major version of datasets. Use DatasetDict.rename_column instead.\n",
      "  dataset.rename_column_(\"label\", \"labels\")\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def encode_batch(batch):\n",
    "  \"\"\"Encodes a batch of input data using the model tokenizer.\"\"\"\n",
    "  return tokenizer(\n",
    "      batch[\"premise\"],\n",
    "      batch[\"hypothesis\"],\n",
    "      max_length=180,\n",
    "      truncation=True,\n",
    "      padding=\"max_length\"\n",
    "  )\n",
    "\n",
    "# Encode the input data\n",
    "dataset = dataset.map(encode_batch, batched=True)\n",
    "# The transformers model expects the target class column to be named \"labels\"\n",
    "dataset.rename_column_(\"label\", \"labels\")\n",
    "# Transform to pytorch tensors and only output the required columns\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac6c277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/student/hangyav/ext_proj/.anaconda_new/envs/adapters/lib/python3.9/site-packages/transformers/adapters/models/bert.py:245: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "/mounts/Users/student/hangyav/ext_proj/.anaconda_new/envs/adapters/lib/python3.9/site-packages/transformers/adapters/models/bert.py:223: FutureWarning: This class has been renamed to `BertAdapterModel` in v3. Please use the new class instead as this class might be removed in a future version.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModelWithHeads: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "id2label = {id: label for (id, label) in enumerate(dataset[\"train\"].features[\"labels\"].names)}\n",
    "\n",
    "config = BertConfig.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    id2label=id2label,\n",
    ")\n",
    "model = BertModelWithHeads.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2fdf9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained adapters we want to fuse\n",
    "model.load_adapter(\"nli/multinli@ukp\", load_as=\"multinli\", with_head=False)\n",
    "model.load_adapter(\"sts/qqp@ukp\", with_head=False)\n",
    "model.load_adapter(\"nli/qnli@ukp\", with_head=False)\n",
    "# Add a fusion layer for all loaded adapters\n",
    "model.add_adapter_fusion(Fuse(\"multinli\", \"qqp\", \"qnli\"))\n",
    "model.set_active_adapters(Fuse(\"multinli\", \"qqp\", \"qnli\"))\n",
    "\n",
    "# Add a classification head for our target task\n",
    "model.add_classification_head(\"cb\", num_labels=len(id2label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "724985b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter_setup = Fuse(\"multinli\", \"qqp\", \"qnli\")\n",
    "model.train_adapter_fusion(adapter_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "630b87f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    learning_rate=5e-5,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    "    logging_steps=200,\n",
    "    output_dir=\"../tmp/notebook_outputs/fusion_visualization\",\n",
    "    overwrite_output_dir=True,\n",
    "    # The next line is important to ensure the dataset labels are properly passed to the model\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "def compute_accuracy(p: EvalPrediction):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\"acc\": (preds == p.label_ids).mean()}\n",
    "\n",
    "trainer = AdapterTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"validation\"],\n",
    "    compute_metrics=compute_accuracy,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56c7d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mounts/Users/student/hangyav/ext_proj/.anaconda_new/envs/adapters/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 250\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:03, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=8, training_loss=0.9666537046432495, metrics={'train_runtime': 4.5864, 'train_samples_per_second': 54.509, 'train_steps_per_second': 1.744, 'total_flos': 29747296170000.0, 'train_loss': 0.9666537046432495, 'epoch': 1.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9eab835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 56\n",
      "  Batch size = 32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.9308117032051086,\n",
       " 'eval_acc': 0.5,\n",
       " 'eval_runtime': 0.4511,\n",
       " 'eval_samples_per_second': 124.141,\n",
       " 'eval_steps_per_second': 4.434,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()  # implicit model.eval() which is needed for fuse attention scores to be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb415b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(premise, hypothesis):\n",
    "    encoded = tokenizer(premise, hypothesis, return_tensors=\"pt\")\n",
    "    if torch.cuda.is_available():\n",
    "        encoded.to(\"cuda\")\n",
    "    logits = model(**encoded)[0]\n",
    "    pred_class = torch.argmax(logits).item()\n",
    "    return id2label[pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "349c39e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'contradiction'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"\"\"\n",
    "``It doesn't happen very often.'' Karen went home\n",
    "happy at the end of the day. She didn't think that\n",
    "the work was difficult.\n",
    "\"\"\",\n",
    "\"the work was difficult\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd95ed27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 180, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bert.encoder.layer[1].output.adapter_fusion_layer[adapter_setup.name].recent_attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "584db38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_fusion_attentions(model_encoder, fusion_name):\n",
    "    return np.array([\n",
    "        layer.output.adapter_fusion_layer[fusion_name].recent_attention.mean(axis=(0, 1))\n",
    "        for layer in model_encoder.layer\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "085191e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eval_fusion_attentions(model, fusion_name, trainer):\n",
    "    res = list()\n",
    "    for batch in trainer.get_eval_dataloader():\n",
    "        batch = trainer._prepare_inputs(batch)\n",
    "        model(**batch)\n",
    "        res.append(get_averaged_fusion_attentions(model.bert.encoder, fusion_name))\n",
    "        \n",
    "    return np.array(res).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a3d29328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "matrix = get_eval_fusion_attentions(model, adapter_setup.name, trainer)\n",
    "ax = sns.heatmap(\n",
    "    matrix,\n",
    "    linewidth=0.5,\n",
    "    square=True,\n",
    "    xticklabels=adapter_setup.name.split(','),\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4efd660",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.heatmap(\n",
    "    matrix,\n",
    "    linewidth=0.5,\n",
    "    square=True,\n",
    "    xticklabels=adapter_setup.name.split(','),\n",
    ")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
